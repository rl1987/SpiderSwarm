# SpiderSwarm

Not much to see here yet. The following description is aspirational. The code is not production-ready yet.

SpiderSwarm is a distributed cloud-native system for scalable web scraping. Based on dataflow programming concepts, it enables declaratively defining web scraping workflows and distributing them across large number of worker nodes in a frictionless way. SpiderSwarm readily scales from single node running on low-powered system to thousands of nodes in cloud deployment. Furthermore, it exposes APIs and can be integrated into end-user facing apps.

